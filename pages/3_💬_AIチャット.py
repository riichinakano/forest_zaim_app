"""
æ—æ¥­è²¡å‹™åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - AIãƒãƒ£ãƒƒãƒˆ

Gemini APIã‚’ä½¿ç”¨ã—ãŸè²¡å‹™ãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
"""

import streamlit as st
import os
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

from modules.gemini_chat import GeminiClient, CodeExecutor
from modules.financial_analyzer import DataLoader, ConversationLogger


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIãƒãƒ£ãƒƒãƒˆ - æ—æ¥­è²¡å‹™åˆ†æ",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()


def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "session_id" not in st.session_state:
        st.session_state.session_id = None

    if "uploaded_files_list" not in st.session_state:
        st.session_state.uploaded_files_list = []

    if "graph_counter" not in st.session_state:
        st.session_state.graph_counter = 0

    if "pending_code" not in st.session_state:
        st.session_state.pending_code = None

    if "pending_question" not in st.session_state:
        st.session_state.pending_question = None


def execute_code_and_display(code, question, api_key, selected_model, selected_model_display, export_formats):
    """ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’è¡¨ç¤º"""
    with st.spinner("ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."):
        result = CodeExecutor.execute_code(code)

        if result["success"]:
            # å›ç­”ã‚’è¡¨ç¤º
            st.markdown(result["answer"])

            # ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
            if result["figure"]:
                st.plotly_chart(result["figure"], use_container_width=True)

                # ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜
                if export_formats:
                    st.session_state.graph_counter += 1
                    saved_paths = CodeExecutor.save_outputs(
                        session_id=st.session_state.session_id,
                        figure=result["figure"],
                        data=result["data"],
                        export_formats=export_formats,
                        graph_index=st.session_state.graph_counter
                    )

            # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
            if result["data"] is not None:
                st.dataframe(result["data"], use_container_width=True)

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            assistant_message = {
                "role": "assistant",
                "content": result["answer"],
                "figure": result["figure"],
                "data": result["data"]
            }
            st.session_state.messages.append(assistant_message)

            # ãƒ­ã‚°ã«ä¿å­˜
            graph_paths = saved_paths if export_formats and result["figure"] else None
            ConversationLogger.save_message(
                st.session_state.session_id,
                role="assistant",
                content=result["answer"],
                code=code,
                graph_paths=graph_paths
            )

            # ä¿ç•™ä¸­ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚¯ãƒªã‚¢
            st.session_state.pending_code = None
            st.session_state.pending_question = None

        else:
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            st.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {result['error']}")

            # è‡ªå‹•ä¿®æ­£ã‚’è©¦ã¿ã‚‹ï¼ˆæœ€å¤§3å›ï¼‰
            st.markdown("ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦å†å®Ÿè¡Œã‚’è©¦ã¿ã¦ã„ã¾ã™...")

            available_files = DataLoader.list_available_files()
            client = GeminiClient(selected_model, api_key)
            conversation_history = ConversationLogger.get_conversation_history(
                st.session_state.session_id
            )

            for attempt in range(3):
                # ã‚¨ãƒ©ãƒ¼ã‚’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã¦ã‚³ãƒ¼ãƒ‰å†ç”Ÿæˆ
                generated_code = client.generate_code(
                    user_question=f"{question}\n\nã€ã‚¨ãƒ©ãƒ¼ã€‘å‰å›ã®ã‚³ãƒ¼ãƒ‰ã§ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{result['error']}\n\nã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ãŸã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
                    available_files=available_files,
                    uploaded_files=st.session_state.uploaded_files_list,
                    conversation_history=conversation_history
                )

                # å†å®Ÿè¡Œ
                result = CodeExecutor.execute_code(generated_code)
                if result["success"]:
                    st.success(f"âœ… ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œã«æˆåŠŸã—ã¾ã—ãŸï¼ˆè©¦è¡Œå›æ•°: {attempt + 1}ï¼‰")
                    st.markdown(result["answer"])

                    if result["figure"]:
                        st.plotly_chart(result["figure"], use_container_width=True)

                    if result["data"] is not None:
                        st.dataframe(result["data"], use_container_width=True)

                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                    assistant_message = {
                        "role": "assistant",
                        "content": result["answer"],
                        "figure": result["figure"],
                        "data": result["data"]
                    }
                    st.session_state.messages.append(assistant_message)

                    # ãƒ­ã‚°ã«ä¿å­˜
                    ConversationLogger.save_message(
                        st.session_state.session_id,
                        role="assistant",
                        content=result["answer"],
                        code=generated_code
                    )

                    # ä¿ç•™ä¸­ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚¯ãƒªã‚¢
                    st.session_state.pending_code = None
                    st.session_state.pending_question = None
                    break
            else:
                st.error("è‡ªå‹•ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è³ªå•ã‚’è¨€ã„æ›ãˆã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                st.session_state.pending_code = None
                st.session_state.pending_question = None


def main():
    """AIãƒãƒ£ãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    initialize_session_state()

    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆ - è²¡å‹™ãƒ‡ãƒ¼ã‚¿åˆ†æ")
    st.markdown("Gemini APIã‚’æ´»ç”¨ã—ãŸè‡ªç„¶è¨€èªã§ã®è²¡å‹™åˆ†æ")
    st.markdown("---")

    # APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("âš ï¸ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.info("`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã« `GEMINI_API_KEY=your_api_key_here` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        st.subheader("1. ãƒ¢ãƒ‡ãƒ«é¸æŠ")
        models = GeminiClient.get_available_models()
        selected_model_display = st.radio(
            "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
            options=list(models.keys()),
            index=0,
            key="model_select"
        )
        selected_model = models[selected_model_display]

        st.markdown("---")

        # å‚è€ƒè³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        st.subheader("2. å‚è€ƒè³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        st.caption("CSV, Excel (.xlsx) å¯¾å¿œ")

        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=["csv", "xlsx"],
            accept_multiple_files=True,
            key="file_uploader"
        )

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        if uploaded_files:
            uploaded_dir = Path("data/uploaded")
            uploaded_dir.mkdir(parents=True, exist_ok=True)

            for uploaded_file in uploaded_files:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{timestamp}_{uploaded_file.name}"
                filepath = uploaded_dir / filename

                # æ—¢ã«ä¿å­˜æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
                if str(filepath) not in st.session_state.uploaded_files_list:
                    with open(filepath, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    st.session_state.uploaded_files_list.append(str(filepath))

            st.success(f"âœ… {len(uploaded_files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º
        if st.session_state.uploaded_files_list:
            with st.expander("ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«", expanded=False):
                for filepath in st.session_state.uploaded_files_list:
                    st.text(Path(filepath).name)

        st.markdown("---")

        # ã‚°ãƒ©ãƒ•ä¿å­˜è¨­å®š
        st.subheader("3. ã‚°ãƒ©ãƒ•ä¿å­˜å½¢å¼")
        export_formats = st.multiselect(
            "ä¿å­˜å½¢å¼ã‚’é¸æŠ",
            options=["HTML", "PNG"],
            default=["HTML"],
            key="export_formats"
        )

        st.markdown("---")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        st.subheader("4. ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³")

        # æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
        theme_input = st.text_input("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ†ãƒ¼ãƒï¼ˆä»»æ„ï¼‰", value="ä¸€èˆ¬", key="theme_input")
        if st.button("ğŸ†• æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹", use_container_width=True):
            session_id = ConversationLogger.create_session(theme_input)
            st.session_state.session_id = session_id
            st.session_state.messages = []
            st.session_state.graph_counter = 0
            st.session_state.pending_code = None
            st.session_state.pending_question = None
            st.success(f"âœ… æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {session_id}")
            st.rerun()

        # ä¼šè©±ä¿å­˜
        if st.session_state.session_id and st.session_state.messages:
            if st.button("ğŸ’¾ ä¼šè©±ã‚’ä¿å­˜", use_container_width=True):
                try:
                    md_path = ConversationLogger.export_markdown(
                        st.session_state.session_id,
                        model_name=selected_model_display
                    )
                    st.success(f"âœ… ä¼šè©±ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                    st.caption(f"ä¿å­˜å…ˆ: {md_path}")
                except Exception as e:
                    st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

        st.markdown("---")

        # æƒ…å ±è¡¨ç¤º
        if st.session_state.session_id:
            st.caption(f"ğŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {st.session_state.session_id}")
        st.caption(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {selected_model_display}")
        st.caption(f"ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(st.session_state.messages)}")

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯é–‹å§‹ã‚’ä¿ƒã™
    if not st.session_state.session_id:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€ŒğŸ†• æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ä¼šè©±ã‚’å§‹ã‚ã¦ãã ã•ã„")
        st.stop()

    # ä¼šè©±å±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # ã‚°ãƒ©ãƒ•ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
            if "figure" in message and message["figure"]:
                st.plotly_chart(message["figure"], use_container_width=True)

            # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
            if "data" in message and message["data"] is not None:
                st.dataframe(message["data"], use_container_width=True)

    # ä¿ç•™ä¸­ã®ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯æ‰¿èªUIã‚’è¡¨ç¤º
    if st.session_state.pending_code:
        with st.chat_message("assistant"):
            with st.expander("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰", expanded=True):
                st.code(st.session_state.pending_code, language="python")

                col1, col2 = st.columns(2)
                with col1:
                    if st.button("â–¶ï¸ å®Ÿè¡Œ", type="primary", key="execute_btn"):
                        execute_code_and_display(
                            st.session_state.pending_code,
                            st.session_state.pending_question,
                            api_key,
                            selected_model,
                            selected_model_display,
                            export_formats
                        )
                        st.rerun()
                with col2:
                    if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", key="cancel_btn"):
                        st.session_state.pending_code = None
                        st.session_state.pending_question = None
                        st.warning("ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                        st.rerun()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    if prompt := st.chat_input("è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": prompt})

        # ãƒ­ã‚°ã«ä¿å­˜
        ConversationLogger.save_message(
            st.session_state.session_id,
            role="user",
            content=prompt
        )

        # Gemini APIã§ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        with st.spinner("ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
            try:
                # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
                available_files = DataLoader.list_available_files()

                # Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
                client = GeminiClient(selected_model, api_key)

                # ä¼šè©±å±¥æ­´ã‚’å–å¾—
                conversation_history = ConversationLogger.get_conversation_history(
                    st.session_state.session_id
                )

                # ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
                generated_code = client.generate_code(
                    user_question=prompt,
                    available_files=available_files,
                    uploaded_files=st.session_state.uploaded_files_list,
                    conversation_history=conversation_history
                )

                # ã‚³ãƒ¼ãƒ‰ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
                is_safe, error_message = CodeExecutor.validate_code(generated_code)

                if not is_safe:
                    st.error(f"âš ï¸ å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_message}")
                    st.markdown("ã‚³ãƒ¼ãƒ‰ã®å†ç”Ÿæˆã‚’è©¦ã¿ã¦ã„ã¾ã™...")

                    # å†ç”Ÿæˆã‚’è©¦ã¿ã‚‹ï¼ˆæœ€å¤§3å›ï¼‰
                    for attempt in range(3):
                        generated_code = client.generate_code(
                            user_question=f"{prompt}\n\nã€æ³¨æ„ã€‘å‰å›ã®ã‚³ãƒ¼ãƒ‰ã§ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_message}\nå®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
                            available_files=available_files,
                            uploaded_files=st.session_state.uploaded_files_list,
                            conversation_history=conversation_history
                        )

                        is_safe, error_message = CodeExecutor.validate_code(generated_code)
                        if is_safe:
                            break

                    if not is_safe:
                        st.error("å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è³ªå•ã‚’è¨€ã„æ›ãˆã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                        st.stop()

                # ã‚³ãƒ¼ãƒ‰ã‚’ä¿ç•™çŠ¶æ…‹ã«è¨­å®š
                st.session_state.pending_code = generated_code
                st.session_state.pending_question = prompt

                # ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦æ‰¿èªUIã‚’è¡¨ç¤º
                st.rerun()

            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.exception(e)

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.caption("æ—æ¥­è²¡å‹™åˆ†æã‚·ã‚¹ãƒ†ãƒ  v1.2.0 - AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ | Powered by Gemini API")


if __name__ == "__main__":
    main()
